{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_jayr oh, i know how budgeting is.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>things aren`t just as easy and simple as they ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i agree. everybody would`ve been excited and t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                             thanks          1\n",
       "1                                               miss          0\n",
       "2                 _jayr oh, i know how budgeting is.         -1\n",
       "3  things aren`t just as easy and simple as they ...          0\n",
       "4  i agree. everybody would`ve been excited and t...         -1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Sentiment_data\\\\train.csv', encoding='latin-1', usecols=['selected_text', 'sentiment'] , nrows=5000)\n",
    "df = df.dropna()\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0, 'neutral': -1})\n",
    "df.selected_text = df.selected_text.str.lower()\n",
    "df.columns = ['text', 'sentiment']\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove special characters and excessive punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Keep only words and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to the dataset\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Rebuild the vocabulary\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize and count word frequencies\n",
    "all_words = ' '.join(df['text']).split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Filter out rare or unwanted tokens\n",
    "min_frequency = 2  # Keep words that appear at least twice\n",
    "vocab = [word for word, count in word_counts.items() if count >= min_frequency]\n",
    "vocab.append('<UNK>')  # Add a placeholder for unknown words\n",
    "\n",
    "# Create word2idx mapping\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2124 2125\n"
     ]
    }
   ],
   "source": [
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "idx2word[\"<UNK>\"] = len(idx2word)\n",
    "\n",
    "print(len(word2idx), len(idx2word))\n",
    "\n",
    "def one_hot_encode(word, word2idx):\n",
    "    if word not in word2idx:\n",
    "        word = \"<UNK>\"\n",
    "    one_hot = np.zeros(len(word2idx))\n",
    "    one_hot[word2idx[word]] = 1\n",
    "    return one_hot\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize weights and biases\n",
    "input_size = len(vocab)\n",
    "hidden_size = 10\n",
    "output_size = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "whx = np.random.randn(hidden_size , input_size)  # (10,33)\n",
    "whh = np.random.randn(hidden_size, hidden_size)  # (10,10)\n",
    "why = np.random.randn(output_size, hidden_size)  # (3,10)\n",
    "bh = np.zeros((hidden_size, 1))  # (10,1)\n",
    "by = np.zeros((output_size, 1))  # (3,1)\n",
    "o0 = np.zeros((hidden_size, 1))  # (10,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "\n",
    "def forward_pass(sentence, whx, whh, why, bh, by, o0):\n",
    "    for word in sentence.split():\n",
    "        x = one_hot_encode(word, word2idx)\n",
    "        x = x.reshape(-1, 1)\n",
    "        h = np.tanh(np.dot(whx, x) + np.dot(whh, o0) + bh)  # (10,33) * (33,1) + (10,10) * (10,1) + (10,1) = (10,1)\n",
    "    y = np.dot(why, h) + by  # (3,10) * (10,1) + (3,1) = (3,1)\n",
    "    o0 = h\n",
    "    return y, h, o0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:01<05:48,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.47590100240935584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:55<07:58,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.482069393321903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [01:39<06:39,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.48051310529828056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [02:33<06:08,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 0.49077761084591165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [03:22<03:55,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Loss: 0.489367847663648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [04:09<03:34,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.4856410858320649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [04:59<03:28,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Loss: 0.47991401877410705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [05:48<02:28,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140, Loss: 0.4736745456482739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [06:38<01:46,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, Loss: 0.4750914531926067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [07:35<00:47,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, Loss: 0.4744818231062563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:27<00:00,  2.54s/it]\n"
     ]
    }
   ],
   "source": [
    "def softmax(y):\n",
    "    exp_y = np.exp(y - np.max(y))  # Subtract max for numerical stability\n",
    "    return exp_y / np.sum(exp_y)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9))  # Add small value to avoid log(0)\n",
    "\n",
    "def backward_pass(y_true, y_pred, o0, h, x):\n",
    "    # Gradients for why and by\n",
    "    dy = y_pred - y_true\n",
    "    dwhy = np.dot(dy, h.T)\n",
    "    dby = dy\n",
    "\n",
    "    # Gradients for whh, bh, and whx\n",
    "    dh = np.dot(why.T, dy) * (1 - h ** 2)  # Derivative of tanh\n",
    "    dwhh = np.dot(dh, o0.T)\n",
    "    dbh = dh\n",
    "    dwhx = np.dot(dh, x.T)\n",
    "\n",
    "    return dwhy, dby, dwhh, dbh, dwhx\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "\n",
    "# Corrected Training Loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for sentence, sentiment in zip(df[\"text\"], df[\"sentiment\"]):\n",
    "        o0 = np.zeros((hidden_size, 1))  # Reset hidden state for each sentence\n",
    "        y_true = np.zeros((output_size, 1))\n",
    "        y_true[sentiment] = 1\n",
    "\n",
    "        # Forward pass\n",
    "        for word in sentence.split():\n",
    "          \n",
    "            x = one_hot_encode(word, word2idx).reshape(-1, 1)\n",
    "            y_pred, h, o0 = forward_pass(word, whx, whh, why, bh, by, o0)\n",
    "\n",
    "        y_pred = softmax(y_pred)\n",
    "        loss = cross_entropy_loss(y_true, y_pred)\n",
    "\n",
    "        # Backward pass\n",
    "        dwhy, dby, dwhh, dbh, dwhx = backward_pass(y_true, y_pred, o0, h, x)\n",
    "\n",
    "        # Update weights and biases\n",
    "        whx -= learning_rate * dwhx\n",
    "        whh -= learning_rate * dwhh\n",
    "        why -= learning_rate * dwhy\n",
    "        bh -= learning_rate * dbh\n",
    "        by -= learning_rate * dby\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testin the model\n",
    "class_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "def predict(sentence, whx, whh, why, bh, by, o0):\n",
    "    o0 = np.zeros((hidden_size, 1))\n",
    "    valid = False\n",
    "    for word in sentence.split():\n",
    "        if word not in word2idx:\n",
    "            continue\n",
    "        valid = True\n",
    "        x = one_hot_encode(word, word2idx).reshape(-1, 1)\n",
    "        y_pred, h, o0 = forward_pass(word, whx, whh, why, bh, by, o0)\n",
    "\n",
    "    if not valid:\n",
    "        return \"Invalid sentence\"\n",
    "\n",
    "    y_pred = softmax(y_pred)\n",
    "    return class_names[np.argmax(y_pred)]\n",
    "\n",
    "predict(' i do not know', whx, whh, why, bh, by, o0)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
